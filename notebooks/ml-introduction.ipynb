{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b871c38-ac12-409d-840a-a68eb4213f74",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "## Learning from data\n",
    "\n",
    "In more established approaches to modelling (e.g. physical based models), our knowledge of the system that is being modelled is encoded as a set of rules. The rules that describe the system comprise a set of parameters that have certain values. Input data is mathematically combined with the parameters to generate predictions. These rules can be based on theory, empircally derived relationships, physical rules or expert judgement. The task of designing a model includes choosing how many parameters are needed to represent the system, what values they should have and how they should be combined with the input data. \n",
    "\n",
    "There are many advantages to this approach to modelling. These include having models that are based on a known understanding of how variables are related (e.g. the principles of physics) and being able to explain how a model has arrived at its prediction. \n",
    "\n",
    "However, there are also many challenges with this approach to developing models. We may not have a complete understanding of the system we are trying to model. The system might be very complex; for example, it is a non-trivial task requiring lots of expertise to write out the rules and equations that describe the global climate system. The resulting physical-based global climate models are incredibly computationally intensive to run. And, some problems don't lend themselves to being expressed as a series of rules and equations; for example, an object detection model that draws boxes around features such as fishing vessels in aerial images or animals in photographs. \n",
    "\n",
    "In these cases, a machine learning approach to developing models might be a suitable alternative. In traditional modelling, input data and a model comprising rules that describe the system are known in advance. The predictions are unknown. In machine learning modelling, the input data and target values are known in advance. The model's rules are unknown. To develop a machine learning model, a computer is shown examples of input data and target values and it learns rules that describe the relationships between the input data and these targets. As the computer sees more examples of input data and targets it updates the model's parameter values to better reflect the relationship between input data and and outputs. Once the model is trained, input data can be fed into the model to generate output predictions. \n",
    "\n",
    "To develop a machine learning model, the following are required:\n",
    "\n",
    "* **Data**\n",
    "* **Model**\n",
    "* **Loss function**\n",
    "* **Optimisation algorithm**\n",
    "* **Evaluation strategy**\n",
    "* **Prediction pipeline**\n",
    "\n",
    "Let's step through each of these concepts, and demonstrate how to develop a machine learning model using Python's <a href=\"https://scikit-learn.org/stable/\" target=\"_blank\">`scikit-learn` package</a>. We will start with a detailed walk through of building a machine learning model to predict plant species richness for different locations in South America. Then, you will need to adapt this workflow to develop a model that predicts a location in Fiji's land cover using spectral reflectance data measured by a sensor on a satellite. \n",
    "\n",
    "### Datasets\n",
    "\n",
    "**South American species richness:** This is the dataset presented in <a href=\"https://arxiv.org/html/2404.06978v1\" target=\"_blank\">Meyer et al. (2024)</a> that includes points across South America representing vegetation surveys where species richness counts were recorded from the <a href=\"https://onlinelibrary.wiley.com/doi/10.1111/geb.13346\" target=\"_blank\">sPlotOpen database</a>. Species richness counts are the target values. Predictor variables included with this dataset are <a href=\"https://developers.google.com/earth-engine/datasets/catalog/WORLDCLIM_V1_BIO#bands\" target=\"_blank\">WorldClim bioclimatic variables</a> and elevation. The bioclimatic variables have the following definitions:\n",
    "\n",
    "* BIO1: Annual Mean Temperature\n",
    "* BIO2: Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "* BIO3: Isothermality (BIO2/BIO7) (×100)\n",
    "* BIO4: Temperature Seasonality (standard deviation ×100)\n",
    "* BIO5: Max Temperature of Warmest Month\n",
    "* BIO6: Min Temperature of Coldest Month\n",
    "* BIO7: Temperature Annual Range (BIO5-BIO6)\n",
    "* BIO8: Mean Temperature of Wettest Quarter\n",
    "* BIO9: Mean Temperature of Driest Quarter\n",
    "* BIO10: Mean Temperature of Warmest Quarter\n",
    "* BIO11: Mean Temperature of Coldest Quarter\n",
    "* BIO12: Annual Precipitation\n",
    "* BIO13: Precipitation of Wettest Month\n",
    "* BIO14: Precipitation of Driest Month\n",
    "* BIO15: Precipitation Seasonality (Coefficient of Variation)\n",
    "* BIO16: Precipitation of Wettest Quarter\n",
    "* BIO17: Precipitation of Driest Quarter\n",
    "* BIO18: Precipitation of Warmest Quarter\n",
    "* BIO19: Precipitation of Coldest Quarter\n",
    "\n",
    "**Fiji Ba land use and land cover:** This is a dataset of points collected across the Ba region of Fiji's main island, Viti Levu. Each point has a land use and land cover class label (an integer value corresponding to a class), which is the target value, and a series of predictor variables representing annual median spectral reflectance values, monthly NDVI values, and topographic data. The spectral reflectance values were derived from cloud free <a href=\"https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR_HARMONIZED\" target=\"_blank\">Sentinel-2 satellite images</a>. This dataset is a subset of data available on the <a href=\"https://pacificdata.org/data/dataset/fiji-land-use-land-cover-labels\" target=\"_blank\">Pacific Data Hub</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f334be6-44bf-4aa6-8e64-778dba300780",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac800d0d-db5e-46fc-a11b-9e7988c6b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "if \"data-geoml\" not in os.listdir(os.getcwd()):\n",
    "    subprocess.run('wget \"https://github.com/envt-5566/geo-ml/raw/main/data/data-geoml.zip\"', shell=True, capture_output=True, text=True)\n",
    "    subprocess.run('unzip \"data-geoml.zip\"', shell=True, capture_output=True, text=True)\n",
    "    if \"data-geoml.zip\" not in os.listdir(os.getcwd()):\n",
    "        print(\"Has a directory called data-geoml been downloaded and placed in your working directory? If not, try re-executing this code chunk\")\n",
    "    else:\n",
    "        print(\"Data download OK\")\n",
    "\n",
    "DATA_PATH = os.path.join(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3954f-0109-48b0-8297-0b2ff8ebe315",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69a120-88b5-4844-9ccf-7dcb60033170",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install mapclassify\n",
    "    !pip install contextily\n",
    "    !pip install pysal\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from math import log\n",
    "\n",
    "# pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aebb1a2-faab-4b38-ae58-51983067f884",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Machine learning model development is all about learning from data. Training a machine learning model involves a computer learning relationships and patterns that map input data to target values. Therefore, to train a machine learning model we need input data and corresponding target values. The input data is often described as predictor variables or features. The target values are often termed labels.\n",
    "\n",
    "In machine learning model development, datasets are often split into a training, validation and test set. \n",
    "\n",
    "### Data splits\n",
    "\n",
    "* **Training data**: This dataset used to train the model and learn rules that map inputs to targets. \n",
    "* **Validation data**: This is a dataset that we can use to evaluate the model during development, get feedback on the training process and experiment with tweaks to the model design. \n",
    "* **Test data**: This is a dataset that we hold out from the model development process. This dataset is used to generate a series of predictions which are compared to known target values. This comparison is an evaluation of how well the model would perform given data it has not seen in training. \n",
    "\n",
    "### Overfitting and generalisation\n",
    "\n",
    "Machine learning models can be incredibly flexible. This means that during training they might learn to fit the training data exactly rather than learning patterns and rules that let the model generalise across a wider variety of unseen data. The case of a model fitting the training data but not generating good predictions on unseen data is called overfitting. Comparing the training error (i.e. the error of the model's predictions using the training split) to the validation error (i.e. the error of the model's predictions using the validation split) can indicate if the model is overfitting. The common signal of overfitting is the training error rate reducing while the validation error rate remains constant (or increases). \n",
    "\n",
    "### Data pre-processing\n",
    "\n",
    "Often, before data can be used for model training it needs to be pre-processed. This task is sometimes called feature engineering. Pre-processing can include data cleaning to remove noisy samples, merging datasets with different structures or computing new variables. \n",
    "\n",
    "A pre-processing step that is necessary for many machine learning tasks is standardising or normalising the input data. For example, it is common practice to standardise data for training neural network models; this involves subtracting the mean of each variable from every data point and dividing by the variable's standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b8d91-64b8-4499-a1e6-7e055bbf6e3d",
   "metadata": {},
   "source": [
    "#### Data import\n",
    "\n",
    "Let's read in a spatial dataset of points across South America where there is a plant species richness count (target values) and predictor variables (bioclimatic variables and elevation). This data is read into a <a href=\"https://geopandas.org/en/stable/getting_started/introduction.html#Concepts\" target=\"_blank\">`GeoDataFrame` object</a>, a container for storing spatial vector datasets in Python programs. `GeoDataFrame`'s have a tabular structure with each example represented by a row and each variable is represented by a column with a special column storing a geometry for locational information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49383b70-1e81-43dc-9a30-67d182f2c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(os.path.join(DATA_PATH, \"plant_species_south_america.gpkg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33afd225-9434-47d2-8a4f-396e2a155515",
   "metadata": {},
   "source": [
    "Call the `head()` method on the `GeoDataFrame` object, `gdf` to print out the first few rows. This gives us a feel for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7054077-7c88-4344-bab2-29e1aa1a8ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74478406-7325-418c-bf45-fe2ce8a36144",
   "metadata": {},
   "source": [
    "We can also call the `explore()` method on `gdf` to render the spatial data on a web map. We're setting the `column` argument to `Species_richness`, this will colour each point on the map according to its species richness value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebf9e2-faba-4342-9647-7dbf31e518fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf.explore(column=\"Species_richness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efe171c-98c2-4950-91ae-a59e0f65116f",
   "metadata": {},
   "source": [
    "#### Data pre-processing\n",
    "\n",
    "Now we have read in our data, we need to create training and test splits. The `scikit-learn` package comes with a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" target=\"_blank\">`train_test_split` function</a>. The requires us to pass in an array of input data (`X`), a vector of output values of the same length as the number of rows in the input data (`y`), the proportion of the data we want to hold out for testing and a random state. Setting the random state is useful for reproducibility; each time we execute this code we will get the same random training and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b2b76-b559-46cb-9612-7032734e5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not needed for model development\n",
    "gdf_tmp = gdf.drop(columns=[\"PlotObservationID\", \"GIVD_ID\", \"Country\", \"Biome\", \"geometry\"])\n",
    "X = gdf_tmp.drop(columns=[\"Species_richness\"])\n",
    "y = gdf_tmp.loc[:, \"Species_richness\"]\n",
    "\n",
    "# set aside 30% of the data as a test split\n",
    "# set the random state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24dd88-6073-4a4f-a536-2dc21e7b2815",
   "metadata": {},
   "source": [
    "Finally, we need to standardise input data before model training. This involves computing the mean and standard deviation for each predictor variable in the training dataset. Then, we subtract the mean from each example and divide by the standard deviation. Crucially, it is important to use the mean and standard deviation computed on the training dataset when standardising the test dataset or new unseen data. Standardising the data helps the model learn and update its parameter values and adjusts for different predictor variables having different scales and ranges of values.\n",
    "\n",
    "`scikit-learn` has a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\" target=\"_blank\">`StandardScaler()` class</a> with a `fit()` method to compute the means and standard deviation of variables in the training set. It also has a `transform()` method to standardise data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007507e4-fb49-49f1-9307-9a7b2494fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7740968-7c0d-44ef-ab2d-05195cefbd6b",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "In machine learning, a model is software the can read in data, generate predictions, store parameters and functions for combining input data and parameters. The choice of what input data is passed into the model, the number of model parameters and operations of functions combining parameters and data reflect how the model represents the system in question. \n",
    "\n",
    "A simple model is a linear regression model:\n",
    "\n",
    "$\\hat{y} = b + w_{1}x_{1} + w_{2}x_{2}$\n",
    "\n",
    "This model takes in two input variables, $x_{1}$ and $x_{2}$, which are multiplied by two parameters called weights, $w_{1}$ and $w_{2}$, followed by an addition with a third parameter called the bias, $b$, to predict an output $\\hat{y}$. The task of training a linear regression model involves estimating the values that $b$, $w_{1}$ and $w_{2}$ should take; this is a simple machine learning task. This model assumes there is a direct linear transformation of input data to predictions. \n",
    "\n",
    "A benefit of many machine learning models is that they are more flexible and can learn a range of non-linear relationships between input predictors and target values. Here, we will work with a machine learning model called a <a href=\"https://d2l.ai/chapter_multilayer-perceptrons/mlp.html\" target=\"_blank\">multi-layer perceptron</a>, a neural network model.\n",
    "\n",
    "You can represent a linear regression model as a simple neural network of one layer.  \n",
    "\n",
    "<img src=\"https://github.com/envt-5566/geo-ml/blob/main/images/linear-model.png?raw=true\"></img>\n",
    "\n",
    "The input variables are multiplied by a weight (equivalent to $w_{n}$) and added to a bias (equivalent to $b$) to create an output.\n",
    "\n",
    "<img src=\"https://github.com/envt-5566/geo-ml/blob/main/images/linear-model-detailed.png?raw=true\"></img>\n",
    "\n",
    "A multi-layer perceptron extends this in two ways. First, hidden layers of neurons are added. These hidden layers allow you to transform the input data into new representations before computing the output. These representations of your input data might be more representative of your target values. Second, the output from a neuron is passed through a nonlinear activation function. This lets you learn nonlinear mappings between input data and target values. \n",
    "\n",
    "<img src=\"https://github.com/envt-5566/geo-ml/blob/main/images/mutli-layer-model.png?raw=true\"></img>\n",
    "\n",
    "A more detailed view of how data would flow through and be transformed by a unit in the hidden layer:\n",
    "\n",
    "<img src=\"https://github.com/envt-5566/geo-ml/blob/main/images/neuron-nonlinear-activation.png?raw=true\"></img>\n",
    "\n",
    "To create a multi-layer perceptron model we use the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\" target=\"_blank\">`MLPRegressor` class</a> from `scikit-learn`. We can set the number and size of the hidden layers in the model by passing a tuple into the `hidden_layer_sizes` argument. For example, passing in `(20, 20,)` would create two hidden layers each with 20 units. We can also set the `random_state` argument to make our model development reproducible (the weights in the model are randomly initialised, so if we don't set a random state we're not guaranteed to train the same model repeatedly even if using the same training data). \n",
    "\n",
    "```\n",
    "regr = MLPRegressor(hidden_layer_sizes=(50,), random_state=4)\n",
    "```\n",
    "\n",
    "When the outcome is numeric (e.g. as in the case of a species richness count here) it is termed a regression machine learning task. This is why we are using `MLPRegressor`. If the outcome is categorical (e.g. a land cover class or a true / false value) it would be a classification task (and we would use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\" target=\"_blank\">`MLPClassifier`</a> to build our model). \n",
    "\n",
    "## Loss functions\n",
    "\n",
    "Loss functions measure the difference between a predicted output and a ground truth output. Model training involves finding parameter values that minimise the loss function.\n",
    "\n",
    "### Regression\n",
    "\n",
    "As the `MLPRegressor` model class is used for regression tasks, it's trained to minimise the mean squared error loss. \n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Where $n$ is the number of examples in the training dataset, $y_{i}$ is the known target value $\\hat{y}_{i}$ is the predicted value by the model. \n",
    "\n",
    "### Classification\n",
    "\n",
    "For classification tasks (i.e. the model is predicting a categorical outcome and not a numeric value), `scikit-learn`'s `MLPClassifier` class uses the cross-entropy loss function (also called the log-loss function). Outcomes in binary classification tasks can have one of two values and outcomes in multi-class classification tasks can have one of many values. \n",
    "\n",
    "Cross-entropy is a measure of the difference between two probability distributions. For classification tasks, we can represent the known target values as a vector where each element corresponds to a class and the actual class has a probability of one (e.g. `targets = [0, 0, 1, 0]` for a four class classification task. Each element in this vector would correspond to a category such as cat, dog, mouse, and bird). The model output will be a vector of probability scores representing predictions of the class given the input data (e.g. `predictions = [0.2, 0.1, 0.6, 0.1]`). Both of these vectors are probability distributions. Cross-entropy can be used to measure the difference between these two probability distributions with a smaller cross-entropy score indicating the predictions align with the ground truth target class. During model training, we seek to adjust the model's weights to minimise the cross-entropy between the target and predictions distribution.\n",
    "\n",
    "As cross-entropy may be less familiar than the mean squared error loss for regression tasks, let's step through computing the cross-entropy using some fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea71394-4834-41a3-9075-7257d91e8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array([0, 0, 1, 0])\n",
    "predictions = np.array([0.2, 0.1, 0.6, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51bbc54-71f2-4430-b16f-d6d2659062f1",
   "metadata": {},
   "source": [
    "The formula for cross-entropy is:\n",
    "\n",
    "$$\n",
    "H(p, q) = - \\sum_{c} p_{c} \\log(q_{c})\n",
    "$$\n",
    "\n",
    "Where $p$ is the actual class probability, $q$ is the predicted class probability, and $c$ indexes the possible classes.\n",
    "\n",
    "The probability values in $q$ have to taken on a value between 0 and 1. The logarithm of a low probability returns a lower negative number than the logarithm of a higher probability. For example, $\\log(0.1) = -2.3$ and $\\log(0.9) = -0.1$. When the model returns a low probability prediction for the target class (e.g. 0.1) this will return a lower negative number when multiplied by 1 (from $p_{c}$ the actual target probability for that class) than when the model returns a high probability for the target class. This negative number gets multiplied by negative one to make it positive; thus, we get a larger positive value when the predicted probability is lower for the target class and we have a higher loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed422c-9406-4c33-8d85-ec27cf889ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(targets, preds):\n",
    "    H = 0\n",
    "    for i in range(0, len(targets)):\n",
    "        H = H + targets[i]*log(preds[i])\n",
    "    H = -1 * H\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c0bd5-b0fb-465f-aa28-acdb1630cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b25c66-04df-488c-be1a-c45410cbb04c",
   "metadata": {},
   "source": [
    "#### Activity!\n",
    "\n",
    "**Change the values in the `predictions` array and compute the cross-entropy. This should give you an intuition as to how the cross-entropy changes as your predictions get better or worse.**\n",
    "\n",
    "When training a machine learning model, we have more than one example. Therefore, we average the cross-entropy loss across all examples in the training dataset. You can read more about the cross-entropy loss <a href=\"https://machinelearningmastery.com/cross-entropy-for-machine-learning/\" target=\"_blank\">here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ddaaf-a206-4ca7-b9ac-91f7bc9129bd",
   "metadata": {},
   "source": [
    "## Optimisation algorithms\n",
    "\n",
    "Optimisation algorithms adjust the model's parameter values to minimise the loss function. That is, these algorithms seek to find a set of parameter values that minimise the difference between the model's predicted outputs and true outputs for a given set of input training data. \n",
    "\n",
    "Initially our model starts with random weights. Then, we feed our input data through the model to generate a prediction. This prediction is compared to a known output value and the loss is computed, the difference between the prediction and the true value. The model's weights are then adjusted slightly to minimise the loss. The optimisation algorithm that adjusts the model's weights is called stochastic gradient descent. This process is repeated many times until the model converges or a stopping criterion is reached. Below, we setup our model to use stochastic gradient descent as the optimisation algorithm by passing `\"sgd\"` to the `solver` argument and set the maximum number of iterations for updating model weights to 500. \n",
    "\n",
    "```\n",
    "regr = MLPRegressor(hidden_layer_sizes=(50,), random_state=4, solver=\"sgd\", max_iter=500)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27075e6-a101-4de9-ac34-842c59dccd23",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "At this point, we are ready to train the model. The `MLPRegressor` class has a `fit()` method. We pass in our scaled predictor variables and target values to the `fit()` method and the model will learn weight values that minimise the loss.\n",
    "\n",
    "Now, let's execute the model creation and training code we've slowly been building up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bdae82-311d-42d3-ad9d-31c9e6e18ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor(hidden_layer_sizes=(50,), random_state=4, solver=\"sgd\", max_iter=500).fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2686506-865f-4370-8192-d6bdaf19268e",
   "metadata": {},
   "source": [
    "## Evaluation stratey\n",
    "\n",
    "The final step of the machine learning model development process is to evaluate the model. This evaluation should give us an indication of how well the model has learnt to relate input data to target values and the performance of the model with new unseen examples. This information helps us judge how suitable the model is for a particular task or application. \n",
    "\n",
    "The *training error* is the difference between the model's prediction and known values for the training examples. This gives us a biased estimate of the model's performance as during training the model has been optimised to map input data to outcome values in the training dataset. \n",
    "\n",
    "What is more relevant to us is the model's *generalisation error* which is an indication of how well the model would perform given a infinite amount of data that is independent of the training dataset but drawn from the same underlying population. We estimate the *generalisation error* using the test split, a sample of data withheld from the model during training. But, note, this is an **estimate** of the generalisation error, it is the test set error, and you should be aware of the limits of your test set. \n",
    "\n",
    "To estimate the model's error we compute a range of performance metrics. For classification tasks, accuracy is a common metric. Accuracy is the percentage of examples in the test set the model correctly labelled. \n",
    "\n",
    "For regression tasks, mean squared error (MSE), mean absolute error (MAE), the root mean squared error (RMSE), and $R^2$ are common metrics. \n",
    "\n",
    "The MSE measures the average of squared distances between the model predicted and true outcome values in the test set. As it measures the squared distance it is more sensitive to cases when the model error is large. \n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 \n",
    "$$\n",
    "\n",
    "The RMSE is the square root of the MSE; it transforms the error metric into the units of the target variable. \n",
    "\n",
    "The MAE is similar but it measures the average of absolute distances between the model predicted and true outcome values in the test set; it is less sensitive to cases when the model error is large.\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "The $R^2$ (also known as the coefficient of determination) measures the amount of variability in the true target values that is explained by the model predictions. The closer the $R^2$ value is to one, the more variability in the test set's true values is captured by the model's predictions. The $R^2$ is a measure of how well the model's predictions fit the true outcomes. \n",
    "\n",
    "$$\n",
    "\\text{R}^2 = 1- \\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \n",
    "$$\n",
    "\n",
    "$\\bar{y}$ is the mean of true outcomes in the test set and $n$ is the number of examples in the test set. \n",
    "\n",
    "We can estimate the model's MSE using the <a href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.mean_squared_error.html\" target=\"_blank\">`mean_squared_error()` function</a> from `scikit-learn`. First, we need to generate some predictions for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6cc8a-0371-442b-91c9-663c1c329805",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = regr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce1165",
   "metadata": {},
   "source": [
    "Next, we can compute the MSE. The `mean_squared_error()` function takes in an array of true values as its first argument and an array of predictions as its second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f925889-b822-44c8-b818-27c980e268b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = mean_squared_error(y_test, y_test_preds)\n",
    "print(f\"The MSE on the test split is: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a6373d",
   "metadata": {},
   "source": [
    "It is a similar process to compute the $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r2 = r2_score(y_test, y_test_preds)\n",
    "print(f\"The R2 on the test split is: {test_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296eb50",
   "metadata": {},
   "source": [
    "#### Activity!\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Can you use the <code>mean_absolute_error()</code> function to compute the MAE? The docs for the MAE function in <code>scikit-learn</code> are <a href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.mean_absolute_error.html\" target=\"_blank\">here</a>.</strong></summary>\n",
    "\n",
    "```\n",
    "test_mae = mean_absolute_error(y_test, y_test_preds)\n",
    "print(f\"The MAE on the test split is: {test_mae}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b604b-66a9-46db-bdda-0d6ba5f9a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7786026c",
   "metadata": {},
   "source": [
    "#### Activity!\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Can you use the <code>mean_squared_error()</code> function to compute the training error? Do you expect the training error to be higher or lower than the test error?</strong></summary>\n",
    "\n",
    "```\n",
    "y_train_preds = regr.predict(X_train_scaled)\n",
    "train_mse = mean_squared_error(y_train, y_train_preds)\n",
    "print(f\"The MSE on the test split is: {test_mse}\")\n",
    "print(f\"The MSE on the train split is: {train_mse}\")\n",
    "```\n",
    "\n",
    "As the model has seen the training data in training, we would expect the MSE to be lower on training set. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97328b0-5ba2-4cb7-80b8-3671fd259de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec515a41-6d88-4179-bec1-73eef28f39dd",
   "metadata": {},
   "source": [
    "## Prediction pipeline\n",
    "\n",
    "Now that we have trained and tested our model, we can use it to generate predictions. Let's predict the species richness for all of our data points and compare them to observed values. \n",
    "\n",
    "Let's create an array of predictor variables for all our data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f1744-d88e-4606-8318-83ff30e44289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not needed for prediction\n",
    "gdf_preds = gdf.drop(columns=[\"PlotObservationID\", \"GIVD_ID\", \"Country\", \"Biome\", \"geometry\"])\n",
    "X_preds = gdf_preds.drop(columns=[\"Species_richness\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e7ab4e-4b52-4af9-928a-2313d994c863",
   "metadata": {},
   "source": [
    "Then, we need to scale the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32ec80-c8dc-4f63-99de-ffe95c96a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preds_scaled = scaler.transform(X_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1eb2cc-deb4-46db-b8c1-02c0ad41173d",
   "metadata": {},
   "source": [
    "Finally, we can generate predictions of species richness for `X_preds_scaled` and append the predictions as a column in our `GeoDataFrame` `gdf_preds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2983cd-3825-4fea-9d34-8dbc918e7c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "y_preds = regr.predict(X_preds_scaled)\n",
    "\n",
    "# append as column back to GeoDataFrame\n",
    "gdf.loc[:, \"Species_richness_preds\"] = y_preds\n",
    "\n",
    "# compute difference between predicted and observed species richness\n",
    "gdf.loc[:, \"Preds_diffs\"] = gdf.loc[:, \"Species_richness_preds\"] - gdf.loc[:, \"Species_richness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f955ed-ec46-4d75-8689-dd9037a8dba8",
   "metadata": {},
   "source": [
    "We can plot our predictions on a web map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d150c-dd4b-4ac6-b1aa-1e0e453162eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.explore(column=\"Species_richness_preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59c2596-dc16-4563-a565-6c3922e213c9",
   "metadata": {},
   "source": [
    "We can also plot the difference between predicted and observed species richness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff1f17-f5bc-497e-a7f7-9f02c52f7308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf.explore(column=\"Preds_diffs\", cmap=\"RdYlBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14840675-8580-42d1-bb0e-3a5f40043523",
   "metadata": {},
   "source": [
    "## Self guided activity! Land cover classification\n",
    "\n",
    "We have worked through an example of how to train and test a machine learning model for a regression task. That is building a model to predict a continuous numeric outcome. However, often we want to build a model to predict a categorical outcome. Land cover classification is an example of a classification task where want to assign a land cover label (e.g. grass, forest, urban, agriculture) to a location on the Earth's surface. \n",
    "\n",
    "Your task here is to adapt the workflow above to build a model that will classify a location's land cover in the Ba region of Fiji based on input predictors derived from satellite images. The input predictors are generated from <a href=\"https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR_HARMONIZED\" target=\"_blank\">Sentinel-2 satellite images</a> which record the spectral reflectance from the Earth's surface with a 10 m spatial resolution and for wavebands spanning the visible, near infrared and shortwave infrared wavelengths. The input predictors also include topographic variables and spectral indices that highlight vegetative, water-related and built-up features. The task is to train a model that relates these input predictors to a land cover label. \n",
    "\n",
    "Let's start by reading in the data and exploring it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5c566-2300-4f96-a674-16cce9662df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_lc = gpd.read_file(os.path.join(DATA_PATH, \"fiji_ba_lulc_s2.geojson\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0b597-04aa-44fa-9ed4-c06f1d25a3f9",
   "metadata": {},
   "source": [
    "The land cover class for a point is stored under the `class` column. \n",
    "\n",
    "The `class` column is the land cover class label for a point. This column stores integer type values. Each integer corresponds to a land cover class:\n",
    "\n",
    "1. water\n",
    "2. mangrove\n",
    "3. bare earth\n",
    "4. urban\n",
    "5. agriculture\n",
    "6. grassland\n",
    "7. shrubs\n",
    "8. trees\n",
    "\n",
    "Let's reclassify the integer values to text labels and visualise this on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb018c0-fa2c-4381-9d75-62e531574227",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    1: \"water\",\n",
    "    2: \"mangrove\",\n",
    "    3: \"bare earth\",\n",
    "    4: \"urban\",\n",
    "    5: \"agriculture\",\n",
    "    6: \"grassland\",\n",
    "    7: \"shrubs\",\n",
    "    8: \"trees\",\n",
    "}\n",
    "\n",
    "gdf_lc.loc[:, \"class_label\"] = gdf_lc[\"class\"].replace(label_map)\n",
    "\n",
    "# alphabetical order\n",
    "cmap = [\n",
    "    \"darkorange\",\n",
    "    \"brown\",\n",
    "    \"darkseagreen\",\n",
    "    \"aquamarine\",\n",
    "    \"olivedrab\",\n",
    "    \"darkgreen\",\n",
    "    \"grey\",\n",
    "    \"blue\",\n",
    "]\n",
    "\n",
    "gdf_lc.explore(column=\"class_label\", categorical=True, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caad40e-18c3-489d-9165-74f974b86970",
   "metadata": {},
   "source": [
    "Let's quickly inspect the first few rows of the `GeoDataFrame`. The columns with headings starting with `B*` are annual average spectral reflectance values for all cloud free observations over a year; the `B*` labelling corresponds to different wavebands (e.g. `B8` is the near infrared band). The columns `gcvi`, `ndbi`, `ndwi`, and `ndvi` are spectral indices that are sensitive to the presence of vegetation condition, chlorophyll, built-up surfaces, and moisture. \n",
    "\n",
    "Integer type labels are used to represent the land cover classes as the model still needs to represent categorical type data in a numeric form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2fbc98-a26b-468e-ac4c-9b694419d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_lc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f2e724-734c-4a45-bb57-10c266b75436",
   "metadata": {},
   "source": [
    "Let's prepare the data for model training by selecting the predictor variables and the outcome labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d33ad3-d831-4094-8a53-031776983984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not needed for model development\n",
    "gdf_tmp = gdf_lc.drop(columns=[\"year\", \"geometry\", \"class_label\"])\n",
    "X = gdf_tmp.drop(columns=[\"class\"])\n",
    "y = gdf_tmp.loc[:, \"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17d11a-eef9-48d3-8c48-fc145f9ffd6c",
   "metadata": {},
   "source": [
    "#### Activity!\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Can you create train and test splits of the predictors and outcome labels to prepare the data for land cover classification model development? Can you use the <code>StandardScaler</code> object to standardise the predictor variables?</strong></summary>\n",
    "\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "lc_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = lc_scaler.transform(X_train)\n",
    "X_test_scaled = lc_scaler.transform(X_test)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596bf91d-1adb-4056-b0b5-e06757dc80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07a700-41d5-4e08-bd7a-a33ed134e766",
   "metadata": {},
   "source": [
    "#### Activity!\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Can you use the dataset that you have just prepared to train a classification model? Here, you will need to use the <code>MLPClassifier</code> from <code>scikit-learn</code>? Use the <code>scikit-learn</code> documentation to see how to adapt the regression workflow implemented above to work with the <code>MLPClassifier</code> model.</strong></summary>\n",
    "\n",
    "```\n",
    "cls = MLPClassifier(hidden_layer_sizes=(10,), random_state=4, solver=\"sgd\", max_iter=500).fit(X_train_scaled, y_train)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d06da2-a3a7-4c2d-a188-f4d0a0240e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196e0d7-01b7-4bc4-af91-584f8cbd0670",
   "metadata": {},
   "source": [
    "#### Activity!\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Can you estimate the accuracy of the trained classifier using the test split? Look at the <code>scikit-learn</code> documentation for computing the accuracy metric. Why is the accuracy a suitable metric for classification tasks?</strong></summary>\n",
    "\n",
    "```\n",
    "y_test_preds = cls.predict(X_test_scaled)\n",
    "test_acc = accuracy_score(y_test, y_test_preds)\n",
    "print(f\"The accuracy on the test split is: {test_acc}\")\n",
    "```\n",
    "\n",
    "The accuracy is more suitable for classification tasks as the outcome is categorical. The accuracy tells us the proportion of times our model assigned the correct class label to a data point in the test split. Categorical values do not have a scale that lets us measure how close or far they are from a true value (i.e. they are not aligned as numeric values on a ratio scale). Therefore, it does not make sense to use metrics like mean absolute error or mean squared error for categorical data. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd390c-cc9b-4a32-97ec-137e1c7f8f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
